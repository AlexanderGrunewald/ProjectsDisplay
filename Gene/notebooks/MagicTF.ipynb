{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import magic\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(optim,lr):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(250, activation='relu'), # sequential NN with descending layers sizes\n",
    "        layers.Dense(200, activation='relu'),\n",
    "        layers.Dense(150, activation='relu'),\n",
    "        layers.Dense(134)\n",
    "    ])\n",
    "    model.compile(loss=tf.keras.metrics.mean_squared_error,\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')], # using RMSE b/c for values <1 MSE may\n",
    "                  optimizer=optim(lr))                     # make the error look smaller than it actually is\n",
    "    return model\n",
    "def plot_loss(history):\n",
    "    '''\n",
    "    plots the loss function for the training and validation data\n",
    "    '''\n",
    "    plt.plot(np.array(history.history['loss'])**0.5, label='loss')\n",
    "    plt.plot(np.array(history.history['val_loss'])**0.5, label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.legend()\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gex = ad.read_h5ad(\"Gex_processed_training.h5ad\") # gex is gene expression which are RNA; Training data input\n",
    "train_adt = ad.read_h5ad(\"Adt_processed_training.h5ad\") # adt is protein; Training data response\n",
    "\n",
    "test_gex = ad.read_h5ad(\"Gex_processed_testing.h5ad\") # gex is gene expression which are RNA; Training data input\n",
    "test_adt = ad.read_h5ad(\"Adt_processed_testing.h5ad\") # adt is protein; Training data response\n",
    "\n",
    "data = ad.concat([train_gex,test_gex])\n",
    "targets = ad.concat([train_adt,test_adt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gex.obsm['Normalized'] = normalize(train_gex.X.toarray())\n",
    "test_gex.obsm['Normalized'] = normalize(test_gex.X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MAGIC...\n",
      "  Running MAGIC on 42123 cells and 13953 genes.\n",
      "  Calculating graph and diffusion operator...\n",
      "    Calculating PCA...\n",
      "    Calculated PCA in 23.76 seconds.\n",
      "    Calculating KNN search...\n",
      "    Calculated KNN search in 89.39 seconds.\n",
      "    Calculating affinities...\n",
      "    Calculated affinities in 87.22 seconds.\n",
      "  Calculated graph and diffusion operator in 200.42 seconds.\n",
      "  Running MAGIC with `solver='exact'` on 13953-dimensional data may take a long time. Consider denoising specific genes with `genes=<list-like>` or using `solver='approximate'`.\n",
      "  Calculating imputation...\n",
      "  Calculated imputation in 29.05 seconds.\n",
      "Calculated MAGIC in 230.08 seconds.\n"
     ]
    }
   ],
   "source": [
    "magic_operator = magic.MAGIC()\n",
    "X_magic_train = magic_operator.fit_transform(train_gex.obsm['Normalized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating MAGIC...\n",
      "  Running MAGIC on 24052 cells and 13953 genes.\n",
      "  Calculating graph and diffusion operator...\n",
      "    Calculating PCA...\n",
      "    Calculated PCA in 12.31 seconds.\n",
      "    Calculating KNN search...\n",
      "    Calculated KNN search in 20.82 seconds.\n",
      "    Calculating affinities...\n",
      "    Calculated affinities in 19.74 seconds.\n",
      "  Calculated graph and diffusion operator in 52.90 seconds.\n",
      "  Running MAGIC with `solver='exact'` on 13953-dimensional data may take a long time. Consider denoising specific genes with `genes=<list-like>` or using `solver='approximate'`.\n",
      "  Calculating imputation...\n",
      "  Calculated imputation in 16.26 seconds.\n",
      "Calculated MAGIC in 70.66 seconds.\n"
     ]
    }
   ],
   "source": [
    "magic_operator = magic.MAGIC()\n",
    "X_magic_test = magic_operator.fit_transform(test_gex.obsm['Normalized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_gex\n",
    "del test_gex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_trans = PCA(n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_res = pca_trans.fit_transform(X_magic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_comp = pca_trans.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(X_magic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_meaned = X_magic_test-train_mean\n",
    "X_test_pca = np.dot(X_test_meaned,old_comp.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1727 - rmse: 0.4155 - val_loss: 0.1083 - val_rmse: 0.3290\n",
      "Epoch 2/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1171 - rmse: 0.3421 - val_loss: 0.0986 - val_rmse: 0.3141\n",
      "Epoch 3/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1107 - rmse: 0.3328 - val_loss: 0.0964 - val_rmse: 0.3105\n",
      "Epoch 4/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1076 - rmse: 0.3280 - val_loss: 0.0963 - val_rmse: 0.3103\n",
      "Epoch 5/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1055 - rmse: 0.3248 - val_loss: 0.0955 - val_rmse: 0.3090\n",
      "Epoch 6/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1041 - rmse: 0.3227 - val_loss: 0.0940 - val_rmse: 0.3066\n",
      "Epoch 7/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1031 - rmse: 0.3211 - val_loss: 0.0922 - val_rmse: 0.3036\n",
      "Epoch 8/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1022 - rmse: 0.3197 - val_loss: 0.0918 - val_rmse: 0.3029\n",
      "Epoch 9/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1014 - rmse: 0.3185 - val_loss: 0.0916 - val_rmse: 0.3026\n",
      "Epoch 10/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1007 - rmse: 0.3174 - val_loss: 0.0921 - val_rmse: 0.3035\n",
      "Epoch 11/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1001 - rmse: 0.3164 - val_loss: 0.0907 - val_rmse: 0.3011\n",
      "Epoch 12/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0996 - rmse: 0.3155 - val_loss: 0.0927 - val_rmse: 0.3044\n",
      "Epoch 13/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0990 - rmse: 0.3146 - val_loss: 0.0909 - val_rmse: 0.3014\n",
      "Epoch 14/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0986 - rmse: 0.3139 - val_loss: 0.0902 - val_rmse: 0.3003\n",
      "Epoch 15/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0981 - rmse: 0.3132 - val_loss: 0.0900 - val_rmse: 0.3000\n",
      "Epoch 16/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0978 - rmse: 0.3127 - val_loss: 0.0904 - val_rmse: 0.3007\n",
      "Epoch 17/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0974 - rmse: 0.3120 - val_loss: 0.0901 - val_rmse: 0.3001\n",
      "Epoch 18/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0971 - rmse: 0.3116 - val_loss: 0.0893 - val_rmse: 0.2989\n",
      "Epoch 19/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0968 - rmse: 0.3112 - val_loss: 0.0892 - val_rmse: 0.2987\n",
      "Epoch 20/40\n",
      "2238/2238 [==============================] - 3s 2ms/step - loss: 0.0966 - rmse: 0.3107 - val_loss: 0.0894 - val_rmse: 0.2991\n",
      "Epoch 21/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0963 - rmse: 0.3103 - val_loss: 0.0901 - val_rmse: 0.3002\n",
      "Epoch 22/40\n",
      "2238/2238 [==============================] - 3s 2ms/step - loss: 0.0961 - rmse: 0.3100 - val_loss: 0.0894 - val_rmse: 0.2990\n",
      "Epoch 23/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0959 - rmse: 0.3096 - val_loss: 0.0905 - val_rmse: 0.3009\n",
      "Epoch 24/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0956 - rmse: 0.3093 - val_loss: 0.0894 - val_rmse: 0.2991\n",
      "Epoch 25/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0954 - rmse: 0.3089 - val_loss: 0.0889 - val_rmse: 0.2981\n",
      "Epoch 26/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0953 - rmse: 0.3087 - val_loss: 0.0896 - val_rmse: 0.2993\n",
      "Epoch 27/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0951 - rmse: 0.3084 - val_loss: 0.0889 - val_rmse: 0.2981\n",
      "Epoch 28/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0949 - rmse: 0.3081 - val_loss: 0.0888 - val_rmse: 0.2981\n",
      "Epoch 29/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0947 - rmse: 0.3078 - val_loss: 0.0896 - val_rmse: 0.2993\n",
      "Epoch 30/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0946 - rmse: 0.3075 - val_loss: 0.0887 - val_rmse: 0.2979\n",
      "Epoch 31/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0944 - rmse: 0.3073 - val_loss: 0.0886 - val_rmse: 0.2976\n",
      "Epoch 32/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0943 - rmse: 0.3071 - val_loss: 0.0901 - val_rmse: 0.3002\n",
      "Epoch 33/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0942 - rmse: 0.3068 - val_loss: 0.0890 - val_rmse: 0.2984\n",
      "Epoch 34/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0940 - rmse: 0.3066 - val_loss: 0.0884 - val_rmse: 0.2973\n",
      "Epoch 35/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0939 - rmse: 0.3065 - val_loss: 0.0885 - val_rmse: 0.2975\n",
      "Epoch 36/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0938 - rmse: 0.3062 - val_loss: 0.0893 - val_rmse: 0.2988\n",
      "Epoch 37/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0937 - rmse: 0.3061 - val_loss: 0.0885 - val_rmse: 0.2975\n",
      "Epoch 38/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0936 - rmse: 0.3059 - val_loss: 0.0886 - val_rmse: 0.2977\n",
      "Epoch 39/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0934 - rmse: 0.3056 - val_loss: 0.0905 - val_rmse: 0.3009\n",
      "Epoch 40/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0933 - rmse: 0.3055 - val_loss: 0.0877 - val_rmse: 0.2962\n"
     ]
    }
   ],
   "source": [
    "MLP_model = build_and_compile_model(tf.keras.optimizers.Adamax,0.001)\n",
    "history = MLP_model.fit(pca_res,train_adt.X.toarray(),validation_split=0.15,epochs=40,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 1s 789us/step\n"
     ]
    }
   ],
   "source": [
    "pred = MLP_model.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983102312650861"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_adt.X.toarray(),pred,squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack([X_magic_train,X_magic_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "pca_ex = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ex = pca_ex[:len(X_magic_train)]\n",
    "X_test_ex = pca_ex[len(X_magic_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42123, 50)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24052, 50)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2238/2238 [==============================] - 5s 2ms/step - loss: 0.1715 - rmse: 0.4141 - val_loss: 0.1064 - val_rmse: 0.3262\n",
      "Epoch 2/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1174 - rmse: 0.3426 - val_loss: 0.1013 - val_rmse: 0.3183\n",
      "Epoch 3/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1108 - rmse: 0.3329 - val_loss: 0.0979 - val_rmse: 0.3129\n",
      "Epoch 4/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1075 - rmse: 0.3279 - val_loss: 0.0967 - val_rmse: 0.3110\n",
      "Epoch 5/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1054 - rmse: 0.3247 - val_loss: 0.0936 - val_rmse: 0.3059\n",
      "Epoch 6/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1040 - rmse: 0.3225 - val_loss: 0.0942 - val_rmse: 0.3069\n",
      "Epoch 7/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1028 - rmse: 0.3207 - val_loss: 0.0928 - val_rmse: 0.3046\n",
      "Epoch 8/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1020 - rmse: 0.3194 - val_loss: 0.0926 - val_rmse: 0.3042\n",
      "Epoch 9/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1012 - rmse: 0.3181 - val_loss: 0.0919 - val_rmse: 0.3031\n",
      "Epoch 10/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.1006 - rmse: 0.3171 - val_loss: 0.0909 - val_rmse: 0.3014\n",
      "Epoch 11/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0999 - rmse: 0.3161 - val_loss: 0.0915 - val_rmse: 0.3026\n",
      "Epoch 12/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0994 - rmse: 0.3153 - val_loss: 0.0906 - val_rmse: 0.3010\n",
      "Epoch 13/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0988 - rmse: 0.3143 - val_loss: 0.0900 - val_rmse: 0.3001\n",
      "Epoch 14/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0984 - rmse: 0.3136 - val_loss: 0.0904 - val_rmse: 0.3007\n",
      "Epoch 15/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0979 - rmse: 0.3129 - val_loss: 0.0898 - val_rmse: 0.2996\n",
      "Epoch 16/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0975 - rmse: 0.3123 - val_loss: 0.0908 - val_rmse: 0.3013\n",
      "Epoch 17/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0972 - rmse: 0.3118 - val_loss: 0.0900 - val_rmse: 0.2999\n",
      "Epoch 18/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0969 - rmse: 0.3112 - val_loss: 0.0908 - val_rmse: 0.3013\n",
      "Epoch 19/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0965 - rmse: 0.3107 - val_loss: 0.0896 - val_rmse: 0.2993\n",
      "Epoch 20/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0963 - rmse: 0.3104 - val_loss: 0.0897 - val_rmse: 0.2994\n",
      "Epoch 21/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0961 - rmse: 0.3100 - val_loss: 0.0896 - val_rmse: 0.2993\n",
      "Epoch 22/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0958 - rmse: 0.3096 - val_loss: 0.0889 - val_rmse: 0.2982\n",
      "Epoch 23/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0956 - rmse: 0.3092 - val_loss: 0.0894 - val_rmse: 0.2990\n",
      "Epoch 24/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0954 - rmse: 0.3089 - val_loss: 0.0895 - val_rmse: 0.2992\n",
      "Epoch 25/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0952 - rmse: 0.3086 - val_loss: 0.0895 - val_rmse: 0.2991\n",
      "Epoch 26/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0951 - rmse: 0.3083 - val_loss: 0.0891 - val_rmse: 0.2985\n",
      "Epoch 27/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0949 - rmse: 0.3081 - val_loss: 0.0882 - val_rmse: 0.2970\n",
      "Epoch 28/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0947 - rmse: 0.3077 - val_loss: 0.0894 - val_rmse: 0.2990\n",
      "Epoch 29/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0945 - rmse: 0.3075 - val_loss: 0.0890 - val_rmse: 0.2983\n",
      "Epoch 30/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0945 - rmse: 0.3074 - val_loss: 0.0890 - val_rmse: 0.2984\n",
      "Epoch 31/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0943 - rmse: 0.3070 - val_loss: 0.0886 - val_rmse: 0.2976\n",
      "Epoch 32/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0942 - rmse: 0.3069 - val_loss: 0.0887 - val_rmse: 0.2979\n",
      "Epoch 33/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0940 - rmse: 0.3066 - val_loss: 0.0900 - val_rmse: 0.3001\n",
      "Epoch 34/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0939 - rmse: 0.3064 - val_loss: 0.0888 - val_rmse: 0.2981\n",
      "Epoch 35/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0938 - rmse: 0.3062 - val_loss: 0.0896 - val_rmse: 0.2993\n",
      "Epoch 36/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0936 - rmse: 0.3060 - val_loss: 0.0889 - val_rmse: 0.2981\n",
      "Epoch 37/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0935 - rmse: 0.3059 - val_loss: 0.0886 - val_rmse: 0.2976\n",
      "Epoch 38/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0934 - rmse: 0.3056 - val_loss: 0.0892 - val_rmse: 0.2987\n",
      "Epoch 39/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0933 - rmse: 0.3055 - val_loss: 0.0889 - val_rmse: 0.2981\n",
      "Epoch 40/40\n",
      "2238/2238 [==============================] - 4s 2ms/step - loss: 0.0932 - rmse: 0.3053 - val_loss: 0.0884 - val_rmse: 0.2973\n"
     ]
    }
   ],
   "source": [
    "MLP_model = build_and_compile_model(tf.keras.optimizers.Adamax,0.001)\n",
    "history = MLP_model.fit(X_train_ex,train_adt.X.toarray(),validation_split=0.15,epochs=40,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 [==============================] - 1s 649us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35640544129138524"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = MLP_model.predict(X_test_ex)\n",
    "mean_squared_error(test_adt.X.toarray(),pred,squared=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
